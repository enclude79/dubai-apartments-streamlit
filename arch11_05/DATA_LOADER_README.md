# Система ежедневной загрузки данных API Bayut

Система предназначена для автоматической ежедневной загрузки данных о недвижимости из API Bayut, сохранения их в CSV файлы и загрузки в базу данных PostgreSQL.

## Основные возможности

1. Ежедневная загрузка данных из API Bayut
2. Сохранение данных в CSV файлы с указанием даты
3. Загрузка данных из CSV файлов в базу данных PostgreSQL
4. Перемещение обработанных CSV файлов в архивную папку
5. Инкрементальная загрузка (загрузка только новых данных с даты последнего обновления)
6. Поддержка замещения данных за последний день (для обновления изменившихся объявлений)

## Структура системы

Система состоит из следующих компонентов:

- **daily_property_loader.py** - основной скрипт для загрузки данных из API, сохранения в CSV и загрузки в БД
- **schedule_daily_load.py** - скрипт-планировщик для ежедневного запуска загрузки
- **logs/** - директория с логами выполнения скриптов
- **Api_Bayat/archive/** - архивная директория для обработанных CSV файлов

## Требования

- Python 3.8 или выше
- PostgreSQL 10 или выше
- Библиотеки: requests, pandas, psycopg2, schedule

## Настройка

1. Убедитесь, что у вас созданы все необходимые директории:
   ```bash
   mkdir -p logs Api_Bayat/archive
   ```

2. Установите необходимые зависимости:
   ```bash
   pip install requests pandas psycopg2-binary schedule
   ```

3. Настройте параметры подключения к базе данных в файле `daily_property_loader.py`:
   ```python
   DB_CONFIG = {
       'user': 'admin',
       'password': 'your_password',
       'host': 'localhost',
       'port': '5432',
       'database': 'postgres',
       'table': 'bayut_properties'
   }
   ```

4. Настройте параметры API в файле `daily_property_loader.py`:
   ```python
   API_CONFIG = {
       "url": "https://bayut.p.rapidapi.com/properties/list",
       "headers": {
           "X-RapidAPI-Key": "your_api_key",
           "X-RapidAPI-Host": "bayut.p.rapidapi.com"
       },
       # ...
   }
   ```

## Использование

### Разовый запуск загрузки данных

```bash
python daily_property_loader.py
```

### Настройка планировщика

```bash
# Запуск загрузки немедленно
python schedule_daily_load.py --now

# Запуск планировщика в фоновом режиме
python schedule_daily_load.py --daemon
```

### Настройка времени выполнения

По умолчанию загрузка данных выполняется ежедневно в 02:00. Для изменения времени выполнения установите переменную окружения:

```bash
export DAILY_LOAD_TIME="03:30"
python schedule_daily_load.py --daemon
```

## Логирование

Все операции логируются в файлы в директории `logs/`:

- `logs/property_loader_YYYYMMDD_HHMMSS.log` - логи выполнения загрузки данных
- `logs/scheduler_YYYYMMDD.log` - логи планировщика

## Архивирование CSV файлов

После успешной загрузки данных в базу CSV файлы перемещаются в архивную директорию `Api_Bayat/archive/` с добавлением временной метки к имени файла:

```
Api_Bayat/archive/bayut_properties_sale_20250515_20250515_123456.csv
```

## Принципы реализации

Система реализована с соблюдением принципов SOLID и KISS:

- **Single Responsibility Principle**: Каждый класс имеет только одну причину для изменения
- **Open/Closed Principle**: Система открыта для расширения, но закрыта для модификации
- **Liskov Substitution Principle**: Производные типы могут быть заменены базовыми
- **Interface Segregation Principle**: Классы имеют только необходимые зависимости
- **Dependency Inversion Principle**: Зависимости инвертированы через инъекцию зависимостей
- **KISS (Keep It Simple, Stupid)**: Система реализована максимально просто, без лишних усложнений

## Безопасность

API-ключи и параметры подключения к базе данных хранятся в коде для простоты, но в продакшн-среде рекомендуется:

1. Вынести их в переменные окружения
2. Использовать файл .env для хранения чувствительных данных
3. Не хранить чувствительные данные в системе контроля версий

## Поддержка и развитие

Для развития системы можно реализовать:

1. Добавление уведомлений о результатах загрузки (email, Slack, Telegram)
2. Интеграцию с системой мониторинга
3. Реализацию веб-интерфейса для управления загрузкой данных
4. Поддержку других API-источников данных 